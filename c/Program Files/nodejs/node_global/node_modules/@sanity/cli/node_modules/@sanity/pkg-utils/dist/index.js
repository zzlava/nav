import path, { resolve, relative, dirname } from "node:path";
import rimraf from "rimraf";
import { register } from "esbuild-register/dist/node";
import pkgUp from "pkg-up";
import findConfig from "find-config";
import fs$1, { statSync, existsSync } from "node:fs";
import { z, ZodError } from "zod";
import chalk from "chalk";
import fs, { writeFile, readFile, readdir, lstat } from "node:fs/promises";
import browserslist from "browserslist";
import config$1 from "@sanity/browserslist-config";
import ts from "typescript";
import { errorMap } from "zod-validation-error";
import { Observable, switchMap } from "rxjs";
import { ExtractorConfig, Extractor } from "@microsoft/api-extractor";
import { mkdirp } from "mkdirp";
import prettier from "prettier";
import { TSDocConfigFile } from "@microsoft/tsdoc-config";
import { parse } from "jsonc-parser";
import { parse as parse$1, print } from "recast";
import typeScriptParser from "recast/parsers/typescript.js";
import { rollup, watch as watch$1 } from "rollup";
import { optimizeLodashImports } from "@optimize-lodash/rollup-plugin";
import alias from "@rollup/plugin-alias";
import { babel, getBabelOutputPlugin } from "@rollup/plugin-babel";
import commonjs from "@rollup/plugin-commonjs";
import json from "@rollup/plugin-json";
import { nodeResolve } from "@rollup/plugin-node-resolve";
import replace from "@rollup/plugin-replace";
import terser from "@rollup/plugin-terser";
import esbuild from "rollup-plugin-esbuild";
import esbuild$1 from "esbuild";
import treeify from "treeify";
import prettyBytes from "pretty-bytes";
import prompts from "prompts";
import getLatestVersion from "get-latest-version";
import gitUrlParse from "git-url-parse";
import { outdent } from "outdent";
import parseGitConfig from "parse-git-config";
import { scan, startWith, distinctUntilChanged } from "rxjs/operators";
import globby from "globby";
import chokidar from "chokidar";
function defineConfig(configOptions) {
  return configOptions;
}
function fileExists(filePath) {
  try {
    return statSync(filePath), !0;
  } catch {
    return !1;
  }
}
const CONFIG_FILE_NAMES = [
  "package.config.ts",
  "package.config.js",
  "package.config.cjs",
  "package.config.mjs"
];
function findConfigFile(cwd) {
  const pkgJsonPath = findConfig("package.json", { cwd });
  if (!pkgJsonPath) return;
  const pkgPath = path.dirname(pkgJsonPath);
  for (const fileName of CONFIG_FILE_NAMES) {
    const configPath = path.resolve(pkgPath, fileName);
    if (fileExists(configPath))
      return configPath;
  }
}
async function loadConfig(options) {
  const { cwd } = options, pkgPath = await pkgUp({ cwd });
  if (!pkgPath) return;
  const root = path.dirname(pkgPath), configFile = await findConfigFile(root);
  if (!configFile || !configFile.startsWith(cwd))
    return;
  const esbuildOptions = { extensions: [".js", ".mjs", ".ts"] }, { unregister } = globalThis.__DEV__ ? { unregister: () => {
  } } : register(esbuildOptions), mod = require(configFile);
  return unregister(), mod?.default || mod || void 0;
}
function resolveConfigProperty(prop, initialValue) {
  return prop ? typeof prop == "function" ? prop(initialValue) : prop : initialValue;
}
const DEFAULT_BROWSERSLIST_QUERY = config$1;
function isRecord(value) {
  return !!value && !Array.isArray(value) && typeof value == "object";
}
const pkgSchema = z.object({
  type: z.optional(z.enum(["commonjs", "module"])),
  name: z.string(),
  version: z.string(),
  license: z.string(),
  bin: z.optional(z.record(z.string())),
  dependencies: z.optional(z.record(z.string())),
  devDependencies: z.optional(z.record(z.string())),
  peerDependencies: z.optional(z.record(z.string())),
  source: z.optional(z.string()),
  main: z.optional(z.string()),
  browser: z.optional(z.record(z.string())),
  module: z.optional(z.string()),
  types: z.optional(z.string()),
  exports: z.optional(
    z.record(
      z.union([
        z.custom((val) => /^\.\/.*\.json$/.test(val)),
        z.custom((val) => /^\.\/.*\.css$/.test(val)),
        z.object({
          types: z.optional(z.string()),
          source: z.optional(z.string()),
          browser: z.optional(
            z.object({
              source: z.string(),
              import: z.optional(z.string()),
              require: z.optional(z.string())
            })
          ),
          "react-compiler": z.optional(
            // z.union([
            // @TODO add support for a string shortcut
            // z.string(),
            z.object({
              source: z.optional(z.string()),
              default: z.string()
            })
            // ]),
          ),
          node: z.optional(
            z.object({
              source: z.optional(z.string()),
              import: z.optional(z.string()),
              require: z.optional(z.string())
            })
          ),
          import: z.optional(z.string()),
          require: z.optional(z.string()),
          default: z.string()
        }),
        z.object({
          types: z.optional(z.string()),
          svelte: z.string(),
          default: z.optional(z.string())
        })
      ])
    )
  ),
  browserslist: z.optional(z.union([z.string(), z.array(z.string())])),
  sideEffects: z.optional(z.union([z.boolean(), z.array(z.string())])),
  // @TODO type this properly
  typesVersions: z.optional(z.any())
}), typoMap = /* @__PURE__ */ new Map();
for (const key of pkgSchema.keyof()._def.values)
  typoMap.set(key.toUpperCase(), key);
function validatePkg(input) {
  const pkg = pkgSchema.parse(input), invalidKey = Object.keys(input).find((key) => {
    const needle = key.toUpperCase();
    return typoMap.has(needle) ? typoMap.get(needle) !== key : !1;
  });
  if (invalidKey)
    throw new TypeError(
      `
- package.json: "${invalidKey}" is not a valid key. Did you mean "${typoMap.get(invalidKey.toUpperCase())}"?`
    );
  return pkg;
}
async function loadPkg(options) {
  const { cwd } = options, pkgPath = await pkgUp({ cwd });
  if (!pkgPath) throw new Error("no package.json found");
  const buf = await fs.readFile(pkgPath), raw = JSON.parse(buf.toString());
  return validatePkg(raw), raw;
}
function assertLast(a, arr) {
  const aIdx = arr.indexOf(a);
  return aIdx === -1 ? !0 : aIdx === arr.length - 1;
}
function assertOrder(a, b, arr) {
  const aIdx = arr.indexOf(a), bIdx = arr.indexOf(b);
  return aIdx === -1 || bIdx === -1 ? !0 : aIdx < bIdx;
}
async function loadPkgWithReporting(options) {
  const { cwd, logger, strict, legacyExports } = options;
  try {
    const pkg = await loadPkg({ cwd });
    let shouldError = !1;
    if (strict && (legacyExports && pkg.type === "commonjs" && (shouldError = !0, logger.error(
      'the `type` field in `./package.json` shouldn\'t be "commonjs" when `legacyExports` is set to true)'
    )), !legacyExports && !pkg.type && (shouldError = !0, logger.error(
      'the `type` field in `./package.json` must be either "module" or "commonjs")'
    ))), pkg.exports) {
      const _exports = Object.entries(pkg.exports);
      for (const [expPath, exp] of _exports) {
        if (typeof exp == "string" || "svelte" in exp)
          continue;
        const keys = Object.keys(exp);
        exp.types && (shouldError = !0, logger.error(
          `exports["${expPath}"]: the \`types\` condition shouldn't be used as dts files are generated in such a way that both CJS and ESM is supported`
        )), exp.module && (shouldError = !0, logger.error(
          `exports["${expPath}"]: the \`module\` condition shouldn't be used as it's not well supported in all bundlers.`
        )), exp.node ? (exp.import && exp.node.import && !assertOrder("node", "import", keys) && (shouldError = !0, logger.error(
          `exports["${expPath}"]: the \`node\` property should come before the \`import\` property`
        )), exp.node.module && (shouldError = !0, logger.error(
          `exports["${expPath}"]: the \`node.module\` condition shouldn't be used as it's not well supported in all bundlers. A better strategy is to refactor the codebase to no longer be vulnerable to the "dual package hazard"`
        )), !exp.node.source && exp.node.import && (exp.node.require || exp.require) && (exp.node.import.endsWith(".cjs.js") || exp.node.import.endsWith(".cjs.mjs")) && (shouldError = !0, logger.error(
          `exports["${expPath}"]: the \`node.import\` re-export pattern shouldn't be used as it's not well supported in all bundlers. A better strategy is to refactor the codebase to no longer be vulnerable to the "dual package hazard"`
        )), exp.require && exp.node.require && exp.require === exp.node.require ? (shouldError = !0, logger.error(
          `exports["${expPath}"]: the \`node.require\` property isn't necessary as it's identical to \`require\``
        )) : exp.require && exp.node.require && !assertOrder("node", "require", keys) && (shouldError = !0, logger.error(
          `exports["${expPath}"]: the \`node\` property should come before the \`require\` property`
        ))) : assertOrder("import", "require", keys) || logger.warn(
          `exports["${expPath}"]: the \`import\` property should come before the \`require\` property`
        ), assertLast("default", keys) || (shouldError = !0, logger.error(
          `exports["${expPath}"]: the \`default\` property should be the last property`
        ));
      }
    }
    return shouldError && process.exit(1), pkg;
  } catch (err) {
    if (err instanceof ZodError)
      for (const issue of err.issues) {
        if (issue.code === "invalid_type") {
          logger.error(
            [
              `\`${formatPath(issue.path)}\` `,
              `in \`./package.json\` must be of type ${chalk.magenta(issue.expected)} `,
              `(received ${chalk.magenta(issue.received)})`
            ].join("")
          );
          continue;
        }
        logger.error(issue);
      }
    else
      logger.error(err);
    process.exit(1);
  }
}
function formatPath(segments) {
  return segments.map((s, idx) => idx === 0 ? s : typeof s == "number" ? `[${s}]` : s.startsWith(".") ? `["${s}"]` : `.${s}`).join("");
}
const fileEnding = /\.[mc]?js$/, dtsEnding = ".d.ts", defaultEnding = ".js", legacyEnding = `.esm${defaultEnding}`, mjsEnding = ".mjs", cjsEnding = ".cjs", mtsEnding = ".d.mts", ctsEnding = ".d.cts";
function getTargetPaths(_type, expOrBundle) {
  const type = _type === "module" ? "module" : "commonjs", set = /* @__PURE__ */ new Set();
  return expOrBundle?.import && set.add(expOrBundle.import.replace(fileEnding, type === "module" ? dtsEnding : mtsEnding)), expOrBundle?.require && set.add(expOrBundle.require.replace(fileEnding, type === "commonjs" ? dtsEnding : ctsEnding)), isPkgExport$1(expOrBundle) && (expOrBundle.browser?.source || (expOrBundle.browser?.import && set.add(
    expOrBundle.browser.import.replace(fileEnding, type === "module" ? dtsEnding : mtsEnding)
  ), expOrBundle.browser?.require && set.add(
    expOrBundle.browser.require.replace(
      fileEnding,
      type === "commonjs" ? dtsEnding : ctsEnding
    )
  )), expOrBundle.node?.source || (expOrBundle.node?.import && set.add(
    expOrBundle.node.import.replace(fileEnding, type === "module" ? dtsEnding : mtsEnding)
  ), expOrBundle.node?.require && set.add(
    expOrBundle.node.require.replace(fileEnding, type === "commonjs" ? dtsEnding : ctsEnding)
  )), expOrBundle["react-compiler"]?.source || expOrBundle["react-compiler"]?.default && set.add(
    expOrBundle["react-compiler"].default.replace(
      fileEnding,
      type === "module" ? dtsEnding : mtsEnding
    )
  )), Array.from(set);
}
function isPkgExport$1(exp) {
  return exp?.browser || exp?.node || exp?.default;
}
const pkgExtMap = {
  // pkg.type: "commonjs"
  commonjs: {
    commonjs: defaultEnding,
    esm: mjsEnding
  },
  // pkg.type: "module"
  module: {
    commonjs: cjsEnding,
    esm: defaultEnding
  },
  // package.config.legacyExports: true
  legacy: legacyEnding
};
function validateExports(_exports, options) {
  const { pkg } = options, type = pkg.type || "commonjs", ext = pkgExtMap[type], errors = [];
  for (const exp of _exports)
    exp.require && !exp.require.endsWith(ext.commonjs) && errors.push(
      `package.json with \`type: "${type}"\` - \`exports["${exp._path}"].require\` must end with "${ext.commonjs}"`
    ), exp.import && !exp.import.endsWith(ext.esm) && errors.push(
      `package.json with \`type: "${type}"\` - \`exports["${exp._path}"].import\` must end with "${ext.esm}"`
    );
  return errors;
}
function parseExports(options) {
  const { cwd, pkg, strict, strictOptions: strictOptions2, legacyExports, logger } = options, type = pkg.type || "commonjs", errors = [], report = (kind, message) => {
    kind === "warn" ? logger.warn(message) : errors.push(message);
  };
  if (!pkg.main && strict && strictOptions2.alwaysPackageJsonMain !== "off" && report(strictOptions2.alwaysPackageJsonMain, "package.json: `main` must be declared"), !Array.isArray(pkg.files) && strict && strictOptions2.alwaysPackageJsonFiles !== "off" && report(
    strictOptions2.alwaysPackageJsonFiles,
    "package.json: `files` should be used over `.npmignore`"
  ), pkg.source) {
    if (strict && pkg.exports?.["."] && typeof pkg.exports["."] == "object" && "source" in pkg.exports["."] && pkg.exports["."].source === pkg.source)
      errors.push(
        'package.json: the "source" property can be removed, as it is equal to exports["."].source.'
      );
    else if (!pkg.exports && pkg.main) {
      const extMap = pkgExtMap[type], importExport = pkg.main.replace(fileEnding, extMap.esm), requireExport = pkg.main.replace(fileEnding, extMap.commonjs), defaultExport = pkg.main.replace(fileEnding, defaultEnding), maybeBrowserCondition = [];
      if (pkg.browser) {
        const browserConditions = [];
        if (pkg.module && pkg.browser?.[pkg.module])
          browserConditions.push(
            `      "import": ${JSON.stringify(pkg.browser[pkg.module].replace(fileEnding, extMap.esm))}`
          );
        else if (pkg.browser?.[pkg.main])
          browserConditions.push(
            `      "import": ${JSON.stringify(pkg.browser?.[pkg.main].replace(fileEnding, extMap.esm))}`
          );
        else if (legacyExports) {
          const browserImport = pkg.main.replace(fileEnding, `.browser${extMap.esm}`);
          browserConditions.push(`      "import": ${JSON.stringify(browserImport)}`);
        }
        if (pkg.browser?.[pkg.main])
          browserConditions.push(
            `      "require": ${JSON.stringify(pkg.browser[pkg.main].replace(fileEnding, extMap.commonjs))}`
          );
        else if (legacyExports) {
          const browserRequire = pkg.main.replace(fileEnding, `.browser${extMap.commonjs}`);
          browserConditions.push(`      "require": ${JSON.stringify(browserRequire)}`);
        }
        browserConditions.length && maybeBrowserCondition.push(
          '    "browser": {',
          `      "source": ${JSON.stringify(pkg.browser?.[pkg.source] || pkg.source)},`,
          ...browserConditions,
          "    }"
        );
      }
      errors.push(
        ...[
          "package.json: `exports` are missing, it should be:",
          '"exports": {',
          '  ".": {',
          `    "source": ${JSON.stringify(pkg.source)},`,
          // If browser conditions are detected then add them to the suggestion
          ...maybeBrowserCondition.length > 0 ? maybeBrowserCondition : [],
          // If legacy exports are enabled we suggest the full list of exports, if not we can use the terse version
          (legacyExports || type === "commonjs") && `    "import": ${JSON.stringify(importExport)},`,
          (legacyExports || type === "module") && `    "require": ${JSON.stringify(requireExport)},`,
          `    "default": ${JSON.stringify(defaultExport)}`,
          "  },",
          '  "./package.json": "./package.json"',
          "}"
        ].filter(Boolean)
      );
    }
  }
  if (errors.length)
    throw new Error(`
- ` + errors.join(`
- `));
  if (!pkg.exports)
    throw new Error(
      `
- ` + [
        "package.json: `exports` are missing, please set a minimal configuration, for example:",
        '"exports": {',
        '  ".": {',
        '    "source": "./src/index.js",',
        '    "default": "./dist/index.js"',
        "  },",
        '  "./package.json": "./package.json"',
        "}"
      ].join(`
- `)
    );
  const _exports = [];
  strict && strictOptions2.noPackageJsonTypings !== "off" && "typings" in pkg && report(strictOptions2.noPackageJsonTypings, "package.json: `typings` should be `types`"), strict && strictOptions2.alwaysPackageJsonTypes !== "off" && !pkg.types && typeof pkg.exports?.["."] == "object" && "source" in pkg.exports["."] && pkg.exports["."].source?.endsWith(".ts") && report(
    strictOptions2.alwaysPackageJsonTypes,
    "package.json: `types` must be declared for the npm listing to show as a TypeScript module."
  ), strict && !pkg.exports["./package.json"] && errors.push('package.json: `exports["./package.json"] must be declared.');
  for (const [exportPath, exportEntry] of Object.entries(pkg.exports))
    if (exportPath.endsWith(".json") || typeof exportEntry == "string" && exportEntry.endsWith(".json"))
      exportPath === "./package.json" && exportEntry !== "./package.json" && errors.push('package.json: `exports["./package.json"]` must be "./package.json".');
    else if (exportPath.endsWith(".css"))
      typeof exportEntry == "string" && !existsSync(resolve(cwd, exportEntry)) ? errors.push(
        `package.json: \`exports[${JSON.stringify(exportPath)}]\`: file does not exist.`
      ) : typeof exportEntry != "string" && errors.push(
        `package.json: \`exports[${JSON.stringify(exportPath)}]\`: export conditions not supported for CSS files.`
      );
    else if (!(isRecord(exportEntry) && "svelte" in exportEntry))
      if (isPkgExport(exportEntry)) {
        const exp = {
          _exported: !0,
          _path: exportPath,
          ...exportEntry
        };
        if (!exp.default) {
          const fallback = type === "module" ? exp.import : exp.require;
          fallback && (exp.default = fallback), legacyExports && (fallback ? errors.push(
            `package.json - \`exports["${exp._path}"].default\` should be set to "${fallback}" when "legacyExports" is true`
          ) : errors.push(
            `package.json - \`exports["${exp._path}"].default\` should be specified when "legacyExports" is true`
          ));
        }
        if (!exp.require && type === "commonjs" && exp.default && (exp.require = exp.default), !exp.import && type === "module" && exp.default && (exp.import = exp.default), exportPath === ".")
          if (exportEntry.require && pkg.main && exportEntry.require !== pkg.main && errors.push(
            'package.json: mismatch between "main" and "exports.require". These must be equal.'
          ), legacyExports) {
            const indexLegacyExport = (exportEntry.import || exportEntry.require || "").replace(
              /(\.esm)?\.[mc]?js$/,
              legacyEnding
            );
            indexLegacyExport !== pkg.module && errors.push(
              `package.json: "module" should be "${indexLegacyExport}" when "legacyExports" is true`
            );
          } else
            exportEntry.import && pkg.module && exportEntry.import !== pkg.module && errors.push(
              'package.json: mismatch between "module" and "exports.import" These must be equal.'
            );
        _exports.push(exp);
      } else isRecord(exportEntry) || errors.push("package.json: exports must be an object");
  if (errors.push(...validateExports(_exports, { pkg })), errors.length)
    throw new Error(`
- ` + errors.join(`
- `));
  return _exports;
}
function isPkgExport(value) {
  return isRecord(value) && "source" in value && typeof value.source == "string";
}
const promptsTypes = {
  string: "text"
};
async function createFromTemplate(options) {
  const { cwd, logger, packagePath, template: templateOrResolver } = options, template = typeof templateOrResolver == "function" ? await templateOrResolver({ cwd, logger, packagePath }) : templateOrResolver;
  logger.log("create new package at", relative(cwd, packagePath));
  const templateOptions = {};
  for (const templateOption of template.options) {
    const templateValidate = templateOption.validate, res = await prompts(
      {
        type: promptsTypes[templateOption.type],
        name: templateOption.name,
        message: templateOption.description,
        validate: templateValidate ? (prev) => templateValidate(prev) : void 0,
        initial: typeof templateOption.initial == "function" ? templateOption.initial(templateOptions) : templateOption.initial
      },
      { onCancel: () => process.exit(0) }
    );
    templateOptions[templateOption.name] = templateOption.parse ? templateOption.parse(res[templateOption.name]) : res[templateOption.name];
  }
  const features = {};
  for (const templateFeature of template.features) {
    const res = templateFeature.optional ? await prompts(
      {
        type: "confirm",
        name: "confirm",
        message: `use ${templateFeature.name}?`,
        initial: templateFeature.initial
      },
      { onCancel: () => process.exit(0) }
    ) : void 0;
    features[templateFeature.name] = res?.confirm || !templateFeature.optional;
  }
  const files = await template.getFiles(templateOptions, features);
  files.sort((a, b) => a.name.localeCompare(b.name));
  for (const file of files) {
    const filePath = resolve(packagePath, file.name);
    await mkdirp(dirname(filePath)), await writeFile(filePath, file.contents.trim() + `
`), logger.success(`wrote ${relative(cwd, filePath)}`);
  }
}
function defineTemplateOption(option) {
  return option;
}
async function loadTSConfig(options) {
  const { cwd, tsconfigPath } = options, configPath = ts.findConfigFile(cwd, ts.sys.fileExists, tsconfigPath);
  if (!configPath)
    return;
  const configFile = ts.readConfigFile(configPath, ts.sys.readFile);
  return ts.parseJsonConfigFileContent(configFile.config, ts.sys, cwd);
}
function createLogger() {
  return {
    /* eslint-disable no-console */
    log: (...args) => {
      console.log(...args);
    },
    info: (...args) => {
      console.log(chalk.blue("[info]"), ...args);
    },
    warn: (...args) => {
      console.log(chalk.yellow("[warning]"), ...args);
    },
    error: (...args) => {
      console.log(chalk.red("[error]"), ...args);
    },
    success: (...args) => {
      console.log(chalk.green("[success]"), ...args);
    }
    /* eslint-enable no-console */
  };
}
function browserslistToEsbuild(browserslistConfig, options = {}) {
  if (!browserslistConfig) {
    const path2 = process.cwd();
    browserslistConfig = browserslist.loadConfig({ path: path2, ...options });
  }
  const SUPPORTED_ESBUILD_TARGETS = [
    "es",
    "chrome",
    "edge",
    "firefox",
    "ios",
    "node",
    "safari",
    "opera",
    "ie"
  ], UNSUPPORTED = ["android 4"], replaces = {
    ios_saf: "ios",
    android: "chrome"
  }, separator = " ";
  return browserslist(browserslistConfig, options).filter((b) => !UNSUPPORTED.some((u) => b.startsWith(u))).map((b) => b === "safari TP" ? browserslist("last 1 safari version")[0] : b).map((b) => b.split(separator)).map((b) => (replaces[b[0]] && (b[0] = replaces[b[0]]), b)).map((b) => (b[1].includes("-") && (b[1] = b[1].slice(0, b[1].indexOf("-"))), b)).map((b) => (b[1].endsWith(".0") && (b[1] = b[1].slice(0, -2)), b)).filter((b) => /^\d+(\.\d+)*$/.test(b[1])).filter((b) => SUPPORTED_ESBUILD_TARGETS.includes(b[0])).reduce((acc, b) => {
    const existingIndex = acc.findIndex((br) => br[0] === b[0]);
    return existingIndex !== -1 ? acc[existingIndex][1] = b[1] : acc.push(b), acc;
  }, []).map((b) => b.join(""));
}
function pathContains(containerPath, itemPath) {
  return !path.relative(containerPath, itemPath).startsWith("..");
}
function findCommonDirPath(filePaths) {
  let ret;
  for (const filePath of filePaths) {
    let dirPath = path.dirname(filePath);
    if (!ret) {
      ret = dirPath;
      continue;
    }
    for (; dirPath !== ret && (dirPath = path.dirname(dirPath), dirPath !== ret); ) {
      if (pathContains(dirPath, ret)) {
        ret = dirPath;
        break;
      }
      if (dirPath === ".") return;
    }
  }
  return ret;
}
function resolveBrowserTarget(versions) {
  const target = versions.filter(
    (version) => version.startsWith("chrome") || version.startsWith("edge") || version.startsWith("firefox") || version.startsWith("ios") || version.startsWith("safari") || version.startsWith("opera")
  );
  if (target.length !== 0)
    return target;
}
function resolveNodeTarget(versions) {
  const target = versions.filter((version) => version.startsWith("node"));
  if (target.length !== 0)
    return target;
}
const toggle = z.union([z.literal("error"), z.literal("warn"), z.literal("off")]), strictOptions = z.object({
  noPackageJsonTypings: toggle.default("error"),
  noImplicitSideEffects: toggle.default("warn"),
  noImplicitBrowsersList: toggle.default("warn"),
  alwaysPackageJsonTypes: toggle.default("error"),
  alwaysPackageJsonMain: toggle.default("error"),
  alwaysPackageJsonFiles: toggle.default("error")
}).strict(), validationSchema = z.object({
  strictOptions: strictOptions.default({})
});
function parseStrictOptions(input) {
  return validationSchema.parse({ strictOptions: input }, { errorMap }).strictOptions;
}
async function resolveBuildContext(options) {
  const {
    config: config2,
    cwd,
    emitDeclarationOnly = !1,
    logger,
    pkg,
    strict,
    tsconfig: tsconfigPath
  } = options, tsconfig = await loadTSConfig({ cwd, tsconfigPath }), strictOptions2 = parseStrictOptions(config2?.strictOptions ?? {});
  let browserslist2 = pkg.browserslist;
  if (!browserslist2) {
    if (strict && strictOptions2.noImplicitBrowsersList !== "off") {
      if (strictOptions2.noImplicitBrowsersList === "error")
        throw new Error(
          '\n- package.json: "browserslist" is missing, set it to `"browserslist": "extends @sanity/browserslist-config"`'
        );
      logger.warn(
        'Could not detect a `browserslist` property in `package.json`, using default configuration. Add `"browserslist": "extends @sanity/browserslist-config"` to silence this warning.'
      );
    }
    browserslist2 = DEFAULT_BROWSERSLIST_QUERY;
  }
  const targetVersions = browserslistToEsbuild(browserslist2);
  if (strict && strictOptions2.noImplicitSideEffects !== "off" && typeof pkg.sideEffects > "u") {
    const msg = "package.json: `sideEffects` is missing, see https://webpack.js.org/guides/tree-shaking/#clarifying-tree-shaking-and-sideeffects for how to define `sideEffects`";
    if (strictOptions2.noImplicitSideEffects === "error")
      throw new Error(msg);
    logger.warn(msg);
  }
  const nodeTarget = resolveNodeTarget(targetVersions), webTarget = resolveBrowserTarget(targetVersions);
  if (!nodeTarget)
    throw new Error("no matching `node` target");
  if (!webTarget)
    throw new Error("no matching `web` target");
  const target = {
    "*": webTarget.concat(nodeTarget),
    browser: webTarget,
    node: nodeTarget
  }, parsedExports = parseExports({
    cwd,
    pkg,
    strict,
    legacyExports: config2?.legacyExports ?? !1,
    strictOptions: strictOptions2,
    logger
  }).reduce((acc, x) => {
    const { _path: exportPath, ...exportEntry } = x;
    return { ...acc, [exportPath]: exportEntry };
  }, {}), exports = resolveConfigProperty(config2?.exports, parsedExports), parsedExternal = [
    ...pkg.dependencies ? Object.keys(pkg.dependencies) : [],
    ...pkg.peerDependencies ? Object.keys(pkg.peerDependencies) : []
  ], external = config2 && Array.isArray(config2.external) ? [...parsedExternal, ...config2.external] : resolveConfigProperty(config2?.external, parsedExternal), externalWithTypes = /* @__PURE__ */ new Set([pkg.name, ...external, ...external.map(transformPackageName)]), bundledDependencies = [
    ...pkg.devDependencies ? Object.keys(pkg.devDependencies) : []
  ].filter(
    // Do not bundle anything that is marked as external
    (_) => !externalWithTypes.has(_)
  ), bundledPackages = config2 && Array.isArray(config2.extract?.bundledPackages) ? [...bundledDependencies, ...config2.extract.bundledPackages] : resolveConfigProperty(config2?.extract?.bundledPackages, bundledDependencies), outputPaths = Object.values(exports).flatMap((exportEntry) => [
    exportEntry.import,
    exportEntry.require,
    exportEntry.browser?.import,
    exportEntry.browser?.require,
    exportEntry.node?.source && exportEntry.node.import,
    exportEntry.node?.source && exportEntry.node.require
    // @TODO implement this
    // exportEntry['react-compiler']?.source && exportEntry['react-compiler']?.default,
  ].filter(Boolean)).map((p) => path.resolve(cwd, p)), commonDistPath = findCommonDirPath(outputPaths);
  if (commonDistPath === cwd)
    throw new Error(
      "all output files must share a common parent directory which is not the root package directory"
    );
  if (commonDistPath && !pathContains(cwd, commonDistPath))
    throw new Error("all output files must be located within the package");
  const configDistPath = config2?.dist ? path.resolve(cwd, config2.dist) : void 0;
  if (configDistPath && commonDistPath && configDistPath !== commonDistPath && !pathContains(configDistPath, commonDistPath))
    throw logger.log(`did you mean to configure \`dist: './${path.relative(cwd, commonDistPath)}'\`?`), new Error("all output files must be located with the configured `dist` path");
  const distPath = configDistPath || commonDistPath;
  if (!distPath)
    throw new Error("could not detect `dist` path");
  return {
    config: config2,
    cwd,
    distPath,
    emitDeclarationOnly,
    exports,
    external,
    bundledPackages,
    files: [],
    logger,
    pkg,
    runtime: config2?.runtime ?? "*",
    strict,
    target,
    ts: {
      config: tsconfig,
      configPath: tsconfigPath
    }
  };
}
function transformPackageName(packageName) {
  if (packageName.startsWith("@types/"))
    return packageName;
  if (packageName.startsWith("@")) {
    const [scope, name] = packageName.split("/");
    return `@types/${scope.slice(1)}__${name}`;
  } else
    return `@types/${packageName}`;
}
function resolveBuildTasks(ctx) {
  const { config: config2, cwd, pkg, target } = ctx, bundles = config2?.bundles || [], tasks = [], exports = Object.entries(ctx.exports || {}).map(
    ([_path, exp]) => ({ _path, ...exp })
  ), dtsTask2 = {
    type: "build:dts",
    entries: []
  }, rollupTasks = {}, rollupLegacyTasks = {}, rollupReactCompilerTask2 = {
    type: "build:react-compiler",
    runtime: "browser",
    format: "esm",
    entries: [],
    target: target.browser
  };
  function addRollupTaskEntry(format2, runtime, entry) {
    const buildId = `${format2}:${runtime}`;
    rollupTasks[buildId] ? rollupTasks[buildId].entries.push(entry) : rollupTasks[buildId] = {
      type: "build:js",
      buildId,
      entries: [entry],
      runtime,
      format: format2,
      target: target[runtime]
    };
  }
  function addRollupLegacyTaskEntry(runtime, entry) {
    const buildId = `esm:${runtime}`;
    rollupLegacyTasks[buildId] ? rollupLegacyTasks[buildId].entries.push(entry) : rollupLegacyTasks[buildId] = {
      type: "build:legacy",
      buildId,
      entries: [entry],
      runtime,
      format: "esm",
      // @TODO set a different target here that is compatible with legacy bundlers and testing tools like brownfield jest
      target: target[runtime]
    };
  }
  function addRollupReactCompilerTaskEntry(entry) {
    rollupReactCompilerTask2.entries.push(entry);
  }
  for (const exp of exports) {
    const importId = path.join(pkg.name, exp._path);
    exp.source?.endsWith(".ts") && dtsTask2.entries.push({
      importId,
      exportPath: exp._path,
      sourcePath: exp.source,
      targetPaths: getTargetPaths(pkg.type, exp)
    }), exp.browser?.source?.endsWith(".ts") && dtsTask2.entries.push({
      importId,
      exportPath: exp._path,
      sourcePath: exp.browser.source,
      targetPaths: getTargetPaths(pkg.type, exp.browser)
    }), exp.node?.source?.endsWith(".ts") && dtsTask2.entries.push({
      importId,
      exportPath: exp._path,
      sourcePath: exp.node.source,
      targetPaths: getTargetPaths(pkg.type, exp.node)
    });
  }
  for (const bundle of bundles)
    if (bundle.source?.endsWith(".ts")) {
      const exportPath = (bundle.import || bundle.require).replace(/\.[mc]?js$/, ""), importId = path.join(pkg.name, exportPath);
      dtsTask2.entries.push({
        importId,
        exportPath,
        sourcePath: bundle.source,
        targetPaths: getTargetPaths(pkg.type, bundle)
      });
    }
  if (dtsTask2.entries.length && tasks.push(dtsTask2), !ctx.emitDeclarationOnly) {
    for (const exp of exports) {
      const output = exp.require;
      output && addRollupTaskEntry("commonjs", ctx.runtime, {
        path: exp._path,
        source: exp.source,
        output
      });
    }
    for (const exp of exports) {
      const output = exp.import;
      output && addRollupTaskEntry("esm", ctx.runtime, {
        path: exp._path,
        source: exp.source,
        output
      });
    }
    for (const exp of exports) {
      const output = exp.browser?.require;
      output && addRollupTaskEntry("commonjs", "browser", {
        path: exp._path,
        source: exp.browser?.source || exp.source,
        output
      });
    }
    for (const exp of exports) {
      const output = exp.browser?.import;
      output && addRollupTaskEntry("esm", "browser", {
        path: exp._path,
        source: exp.browser?.source || exp.source,
        output
      });
    }
    for (const exp of exports) {
      const output = exp["react-compiler"]?.default;
      output && addRollupReactCompilerTaskEntry({
        path: exp._path,
        source: exp["react-compiler"]?.source || exp.source,
        output
      });
    }
    if (rollupReactCompilerTask2.entries.length && tasks.push(rollupReactCompilerTask2), config2?.legacyExports)
      for (const exp of exports) {
        const runtime = exp.browser?.import ? "browser" : ctx.runtime, output = exp.browser?.import || exp.import;
        if (!output) continue;
        const legacyOutput = output.replace(fileEnding, legacyEnding);
        addRollupLegacyTaskEntry(runtime, {
          path: exp._path,
          source: exp.browser?.source || exp.source,
          output: legacyOutput
        });
      }
    for (const bundle of bundles) {
      const idx = bundles.indexOf(bundle);
      bundle.require && addRollupTaskEntry("commonjs", bundle.runtime || ctx.runtime, {
        path: `__$$bundle_cjs_${idx}$$__`,
        source: bundle.source,
        output: bundle.require
      }), bundle.import && addRollupTaskEntry("esm", bundle.runtime || ctx.runtime, {
        path: `__$$bundle_esm_${idx}$$__`,
        source: bundle.source,
        output: bundle.import
      });
    }
    if (tasks.push(...Object.values(rollupTasks), ...Object.values(rollupLegacyTasks)), config2?.legacyExports) {
      for (const exp of exports)
        if (exp._exported && exp._path !== ".") {
          const relativeTargetPath = (exp.browser?.import || exp.import || "").replace(fileEnding, legacyEnding).replace(/\.[^/.]+$/, "");
          relativeTargetPath && fs$1.writeFileSync(
            path.resolve(cwd, `${exp._path}.js`),
            ["// AUTO-GENERATED \u2013 DO NOT EDIT", `export * from '${relativeTargetPath}'`, ""].join(
              `
`
            )
          );
        }
    }
  }
  return tasks;
}
function createSpinner(msg) {
  const startTime = Date.now();
  return console.log(msg), {
    complete: () => {
      console.log(`${chalk.green("[success]")} ${chalk.gray(`${Date.now() - startTime}ms`)}`);
    },
    error: () => {
      console.log(`${chalk.red("[error]")} ${chalk.gray(`${Date.now() - startTime}ms`)}`);
    }
  };
}
function printExtractMessages(ctx, messages) {
  const { cwd, logger } = ctx, warnings = messages.filter((msg) => msg.logLevel === "warning");
  warnings.length && logger.log();
  for (const msg of warnings) {
    const sourceFilePath = msg.sourceFilePath && path.relative(cwd, msg.sourceFilePath);
    msg.messageId !== "TS6307" && logger.log(
      [
        `${chalk.cyan(sourceFilePath || "?")}`,
        `:${chalk.yellow(msg.sourceFileLine)}:${chalk.yellow(msg.sourceFileColumn)}`,
        ` - ${chalk.yellow("warning")} ${chalk.gray(msg.messageId)}
`,
        msg.text,
        `
`
      ].join("")
    );
  }
  const errors = messages.filter((msg) => msg.logLevel === "error");
  !warnings.length && errors.length && logger.log("");
  for (const msg of errors) {
    const sourceFilePath = msg.sourceFilePath && path.relative(cwd, msg.sourceFilePath);
    logger.log(
      [
        `${chalk.cyan(sourceFilePath || "?")}`,
        `:${chalk.yellow(msg.sourceFileLine)}:${chalk.yellow(msg.sourceFileColumn)}`,
        ` - ${chalk.red("error")} ${chalk.gray(msg.messageId)}
`,
        msg.text,
        `
`
      ].join("")
    );
  }
  errors.length && process.exit(1);
}
function printDiagnostic(options) {
  const { cwd, logger, diagnostic } = options;
  if (diagnostic.file && diagnostic.start) {
    const { line, character } = ts.getLineAndCharacterOfPosition(diagnostic.file, diagnostic.start), message = ts.flattenDiagnosticMessageText(diagnostic.messageText, `
`), file = path.relative(cwd, diagnostic.file.fileName), output = [
      `${chalk.yellow(file)}:${chalk.blue(line + 1)}:${chalk.blue(character + 1)} - `,
      `${chalk.gray(`TS${diagnostic.code}:`)} ${message}`
    ].join("");
    diagnostic.category === ts.DiagnosticCategory.Error && logger.error(output), diagnostic.category === ts.DiagnosticCategory.Warning && logger.warn(output), diagnostic.category === ts.DiagnosticCategory.Message && logger.log(output), diagnostic.category === ts.DiagnosticCategory.Suggestion && logger.log(output);
  } else
    logger.log(ts.flattenDiagnosticMessageText(diagnostic.messageText, `
`));
}
async function buildTypes(options) {
  const { cwd, logger, outDir, tsconfig, strict = !1 } = options, compilerOptions = {
    ...tsconfig.options,
    declaration: !0,
    declarationDir: outDir,
    emitDeclarationOnly: !0,
    noEmit: !1,
    noEmitOnError: strict ? !0 : tsconfig.options.noEmitOnError ?? !0,
    outDir
  }, program = ts.createProgram(tsconfig.fileNames, compilerOptions), emitResult = program.emit(), allDiagnostics = ts.getPreEmitDiagnostics(program).concat(emitResult.diagnostics);
  for (const diagnostic of allDiagnostics)
    printDiagnostic({ cwd, logger, diagnostic });
  if (emitResult.emitSkipped && allDiagnostics.filter((diag) => diag.category === ts.DiagnosticCategory.Error).length)
    throw new Error("failed to compile TypeScript definitions");
}
class DtsError extends Error {
  messages;
  constructor(message, messages) {
    super(message), this.messages = messages;
  }
}
function createApiExtractorConfig(options) {
  const {
    bundledPackages,
    distPath,
    exportPath,
    filePath,
    messages,
    projectFolder,
    mainEntryPointFilePath,
    tsconfig,
    tsconfigPath
  } = options, workaroundModulePreserve = tsconfig.options.module === ts.ModuleKind.Preserve, workaroundPaths = !!tsconfig.options.paths, overrideTsconfig = {
    extends: tsconfigPath,
    compilerOptions: {}
  };
  return workaroundModulePreserve && Object.assign(overrideTsconfig.compilerOptions, {
    // Set the equivalent options to `module: 'Preserve'`
    // https://github.com/microsoft/TypeScript/pull/56785/files?file-filters%5B%5D=.js&file-filters%5B%5D=.json&file-filters%5B%5D=.symbols&file-filters%5B%5D=.ts&file-filters%5B%5D=.types&show-viewed-files=true#diff-31d3c12bafea26bc9e8c8a77920c41af0c593206442add70c45a06c063767445
    module: "ESNext",
    moduleResolution: "Bundler",
    esModuleInterop: !0,
    resolveJsonModule: !0
  }), workaroundPaths && Object.assign(overrideTsconfig.compilerOptions, {
    // An empty object replaces whatever is in the original tsconfig file
    paths: {}
  }), {
    apiReport: {
      enabled: !1,
      reportFileName: "<unscopedPackageName>.api.md"
    },
    bundledPackages,
    compiler: workaroundModulePreserve || workaroundPaths ? { overrideTsconfig } : { tsconfigFilePath: tsconfigPath },
    docModel: {
      enabled: !1,
      apiJsonFilePath: path.resolve(distPath, `${exportPath}.api.json`)
    },
    dtsRollup: {
      enabled: !0,
      untrimmedFilePath: path.resolve(distPath, filePath)
      // betaTrimmedFilePath: path.resolve(distPath, filePath.replace('.d.ts', '-beta.d.ts')),
      // publicTrimmedFilePath: path.resolve(distPath, filePath.replace('.d.ts', '-public.d.ts')),
    },
    tsdocMetadata: {
      enabled: !1
    },
    messages,
    mainEntryPointFilePath,
    projectFolder
  };
}
async function createTSDocConfig(opts) {
  const { customTags } = opts;
  if (customTags.length === 0)
    return;
  const tsDocBaseBuf = await readFile(
    require.resolve("@microsoft/api-extractor/extends/tsdoc-base.json")
  ), tsDocBaseConfig = parse(tsDocBaseBuf.toString()), tagDefinitions = (tsDocBaseConfig.tagDefinitions || []).concat(
    customTags.map((t) => ({
      tagName: `@${t.name}`,
      syntaxKind: t.syntaxKind,
      allowMultiple: t.allowMultiple
    }))
  ), supportForTags = { ...tsDocBaseConfig.supportForTags };
  for (const customTag of customTags)
    supportForTags[`@${customTag.name}`] = !0;
  return TSDocConfigFile.loadFromObject({
    ...tsDocBaseConfig,
    noStandardTags: !1,
    tagDefinitions,
    supportForTags
  });
}
async function extractModuleBlocksFromTypes({
  tsOutDir,
  extractResult
}) {
  const program = extractResult.compilerState.program, moduleBlocks = [], sourceFiles = [...program.getSourceFiles()].filter((sourceFile) => sourceFile.fileName.includes(tsOutDir));
  for (const sourceFile of sourceFiles)
    sourceFile.text.includes("declare module") && moduleBlocks.push(...extractModuleBlocks(sourceFile.text));
  return moduleBlocks;
}
function extractModuleBlocks(fileContent) {
  return parse$1(fileContent, {
    parser: typeScriptParser
  }).program.body.filter((node) => node.type === "TSModuleDeclaration").map((node) => print(node).code);
}
const LOG_LEVELS = {
  error: "error",
  info: "info",
  off: "none",
  warn: "warning"
};
function getExtractMessagesConfig(options) {
  const { rules } = options;
  function ruleToLogLevel(key, defaultLevel) {
    const r = rules?.[key];
    return r ? LOG_LEVELS[r] : defaultLevel || "warning";
  }
  return {
    compilerMessageReporting: {
      default: {
        logLevel: "warning"
      }
    },
    extractorMessageReporting: {
      default: {
        logLevel: "warning",
        addToApiReportFile: !1
      },
      "ae-forgotten-export": {
        logLevel: ruleToLogLevel("ae-forgotten-export", "error"),
        addToApiReportFile: !1
      },
      "ae-incompatible-release-tags": {
        logLevel: ruleToLogLevel("ae-incompatible-release-tags", "error"),
        addToApiReportFile: !1
      },
      "ae-internal-missing-underscore": {
        logLevel: ruleToLogLevel("ae-internal-missing-underscore"),
        addToApiReportFile: !1
      },
      "ae-missing-release-tag": {
        logLevel: ruleToLogLevel("ae-missing-release-tag", "error"),
        addToApiReportFile: !1
      },
      "ae-wrong-input-file-type": {
        logLevel: "none",
        addToApiReportFile: !1
      }
    },
    tsdocMessageReporting: {
      default: {
        logLevel: "warning",
        addToApiReportFile: !1
      },
      "tsdoc-link-tag-unescaped-text": {
        logLevel: ruleToLogLevel("tsdoc-link-tag-unescaped-text", "warning"),
        addToApiReportFile: !1
      },
      "tsdoc-undefined-tag": {
        logLevel: ruleToLogLevel("tsdoc-undefined-tag", "error"),
        addToApiReportFile: !1
      },
      "tsdoc-unsupported-tag": {
        logLevel: ruleToLogLevel("tsdoc-unsupported-tag", "none"),
        addToApiReportFile: !1
      }
    }
  };
}
async function extractTypes(options) {
  const {
    bundledPackages,
    customTags,
    distPath,
    exportPath,
    files,
    filePaths,
    projectPath,
    rules,
    sourceTypesPath,
    tmpPath,
    tsconfig,
    tsconfigPath
  } = options, tsdocConfigFile = await createTSDocConfig({
    customTags: customTags || []
  }), filePath = filePaths[0].replace(/\.d\.[mc]ts$/, ".d.ts"), shouldCleanUpDts = !filePaths.includes(filePath), extractorConfig = ExtractorConfig.prepare({
    configObject: createApiExtractorConfig({
      bundledPackages,
      distPath,
      exportPath,
      filePath,
      messages: getExtractMessagesConfig({ rules }),
      projectFolder: projectPath,
      mainEntryPointFilePath: sourceTypesPath,
      tsconfig,
      tsconfigPath
    }),
    configObjectFullPath: void 0,
    tsdocConfigFile,
    packageJsonFullPath: path.resolve(projectPath, "package.json")
  }), messages = [], extractorResult = Extractor.invoke(extractorConfig, {
    // Equivalent to the "--local" command-line parameter
    localBuild: !0,
    // Equivalent to the "--verbose" command-line parameter
    showVerboseMessages: !0,
    // handle messages
    messageCallback(message) {
      messages.push(message), message.handled = !0;
    }
  }), typesPath = path.resolve(distPath, filePath), typesBuf = await fs.readFile(typesPath), prettierConfig = await prettier.resolveConfig(typesPath);
  await mkdirp(path.dirname(typesPath));
  const moduleBlocks = await extractModuleBlocksFromTypes({
    extractResult: extractorResult,
    tsOutDir: tmpPath
  }), code = [typesBuf.toString(), ...moduleBlocks].join(`

`), prettyCode = await prettier.format(code, {
    ...prettierConfig,
    filepath: typesPath
  });
  for (const expFilePath of filePaths) {
    const expTypesPath = path.resolve(distPath, expFilePath);
    await fs.writeFile(expTypesPath, prettyCode), files.push({
      type: "types",
      path: expTypesPath
    });
  }
  return shouldCleanUpDts && await fs.unlink(typesPath), { extractorResult, messages };
}
async function doExtract(ctx, task) {
  const { config: config2, cwd, files, logger, strict, ts: ts2, bundledPackages } = ctx;
  if (!ts2.config || !ts2.configPath)
    return { type: "dts", messages: [], results: [] };
  const { outDir, rootDir = cwd } = ts2.config.options;
  if (!outDir)
    throw new Error("tsconfig.json is missing `compilerOptions.outDir`");
  const tmpPath = path.resolve(outDir, "__tmp__");
  await buildTypes({ cwd, logger, outDir: tmpPath, strict, tsconfig: ts2.config });
  const messages = [], results = [];
  for (const entry of task.entries) {
    const exportPath = entry.exportPath === "." ? "./index" : entry.exportPath, sourceTypesPath = path.resolve(
      tmpPath,
      path.relative(rootDir, path.resolve(cwd, entry.sourcePath)).replace(/\.ts$/, ".d.ts")
    ), targetPaths = entry.targetPaths.map((targetPath) => path.resolve(cwd, targetPath)), filePaths = targetPaths.map((targetPath) => path.relative(outDir, targetPath)), result = await extractTypes({
      bundledPackages: bundledPackages || [],
      customTags: config2?.extract?.customTags,
      cwd,
      distPath: outDir,
      exportPath,
      files,
      filePaths,
      projectPath: cwd,
      rules: config2?.extract?.rules,
      sourceTypesPath,
      tsconfig: ts2.config,
      tmpPath,
      tsconfigPath: path.resolve(cwd, ts2.configPath || "tsconfig.json")
    });
    messages.push(...result.messages);
    const errors = result.messages.filter((msg) => msg.logLevel === "error");
    if (errors.length > 0)
      throw await rimraf(tmpPath), new DtsError(`encountered ${errors.length} errors when extracting types`, errors);
    results.push({ sourcePath: path.resolve(cwd, entry.sourcePath), filePaths: targetPaths });
  }
  return await rimraf(tmpPath), { type: "dts", messages, results };
}
const dtsTask = {
  name: (_ctx, task) => [
    "Build type definitions...",
    "  entries:",
    ...task.entries.map((entry) => entry.targetPaths.map((targetPath) => [
      `    - ${chalk.cyan(entry.importId)}: `,
      `${chalk.yellow(entry.sourcePath)} ${chalk.gray("\u2192")} ${chalk.yellow(targetPath)}`
    ].join("")).join(`
`))
  ].join(`
`),
  exec: (ctx, task) => new Observable((observer) => {
    doExtract(ctx, task).then((result) => {
      observer.next(result), observer.complete();
    }).catch((err) => {
      observer.error(err);
    });
  }),
  complete: (ctx, _task, result) => {
    printExtractMessages(ctx, result.messages);
  },
  error: (ctx, _task, err) => {
    const { logger } = ctx;
    err instanceof DtsError ? printExtractMessages(ctx, err.messages) : err instanceof Error && logger.error(err);
  }
}, dtsWatchTask = {
  name: (_ctx, task) => [
    "build type definitions",
    ...task.entries.map((entry) => entry.targetPaths.map((targetPath) => [
      `    - ${chalk.cyan(entry.importId)}: `,
      `${chalk.yellow(entry.sourcePath)} ${chalk.gray("\u2192")} ${chalk.yellow(targetPath)}`
    ].join("")))
  ].join(`
`),
  exec: (ctx, task) => {
    const { config: config2, cwd, files, logger, strict, ts: tsContext, bundledPackages } = ctx;
    return new Observable((observer) => {
      if (!tsContext.config || !tsContext.configPath) {
        observer.next({ type: "dts", messages: [], results: [] }), observer.complete();
        return;
      }
      const { outDir, rootDir = cwd } = tsContext.config.options;
      if (!outDir) {
        observer.error(new Error("tsconfig.json is missing `compilerOptions.outDir`"));
        return;
      }
      const tmpPath = path.resolve(outDir, "__tmp__");
      buildTypes({
        cwd,
        logger,
        outDir: tmpPath,
        tsconfig: tsContext.config,
        strict
      }).catch((err) => {
        observer.error(err);
      });
      const host = ts.createWatchCompilerHost(
        tsContext.configPath,
        {
          ...tsContext.config.options,
          declaration: !0,
          declarationDir: tmpPath,
          emitDeclarationOnly: !0,
          noEmit: !1,
          noEmitOnError: strict ? !0 : tsContext.config.options.noEmitOnError ?? !0,
          outDir: tmpPath
        },
        ts.sys,
        ts.createEmitAndSemanticDiagnosticsBuilderProgram,
        (diagnostic) => {
          logger.error(ts.flattenDiagnosticMessageText(diagnostic.messageText, `
`));
        },
        (diagnostic) => {
          logger.info(ts.flattenDiagnosticMessageText(diagnostic.messageText, `
`));
        }
      ), origPostProgramCreate = host.afterProgramCreate;
      host.afterProgramCreate = async (program) => {
        origPostProgramCreate?.(program);
        const messages = [], results = [];
        for (const entry of task.entries) {
          const exportPath = entry.exportPath === "." ? "./index" : entry.exportPath, sourceTypesPath = path.resolve(
            tmpPath,
            path.relative(rootDir, path.resolve(cwd, entry.sourcePath)).replace(/\.ts$/, ".d.ts")
          ), targetPaths = entry.targetPaths.map((targetPath) => path.resolve(cwd, targetPath)), filePaths = targetPaths.map((targetPath) => path.relative(outDir, targetPath));
          try {
            const result = await extractTypes({
              bundledPackages: bundledPackages || [],
              customTags: config2?.extract?.customTags,
              cwd,
              distPath: outDir,
              exportPath,
              files,
              filePaths,
              projectPath: cwd,
              rules: config2?.extract?.rules,
              sourceTypesPath,
              tsconfig: tsContext.config,
              tmpPath,
              tsconfigPath: path.resolve(cwd, tsContext.configPath || "tsconfig.json")
            });
            messages.push(...result.messages), results.push({ sourcePath: path.resolve(cwd, entry.sourcePath), filePaths: targetPaths });
          } catch (err) {
            if (err instanceof DtsError)
              messages.push(...err.messages);
            else {
              observer.error(err);
              return;
            }
          }
        }
        observer.next({ type: "dts", messages, results });
      };
      const watchProgram = ts.createWatchProgram(host);
      return () => {
        watchProgram.close(), rimraf.sync(tmpPath);
      };
    });
  },
  complete: (ctx, task, result) => {
    const { logger } = ctx;
    printExtractMessages(ctx, result.messages), logger.success(
      `build type definitions
       ${task.entries.map(
        (entry) => `    - ${chalk.cyan(entry.importId)}: ${chalk.yellow(entry.sourcePath)} ${chalk.gray("\u2192")} ${chalk.yellow(entry.targetPaths.join(", "))}`
      ).join(`
       `)}`
    ), logger.log("");
  },
  error: (ctx, _task, err) => {
    const { logger } = ctx;
    err instanceof DtsError ? printExtractMessages(ctx, err.messages) : err instanceof Error && logger.error(err);
  }
};
function createConsoleSpy(options) {
  const { onRestored } = options || {}, original = {
    log: console.log,
    warn: console.warn,
    error: console.error
  }, messages = [];
  return console.log = (...args) => messages.push({ type: "log", args }), console.warn = (...args) => messages.push({ type: "warn", args }), console.error = (...args) => messages.push({ type: "error", args }), {
    messages,
    restore: () => {
      console.log = original.log, console.warn = original.warn, console.error = original.error, onRestored?.(messages);
    }
  };
}
function resolveRollupConfig(ctx, buildTask) {
  const { format: format2, runtime, target } = buildTask, { config: config2, cwd, exports: _exports, external, distPath, logger, pkg, ts: ts2 } = ctx, isLegacyExports = buildTask.type === "build:legacy", isReactCompiler = buildTask.type === "build:react-compiler", outputExt = isLegacyExports ? pkgExtMap.legacy : pkgExtMap[pkg.type || "commonjs"][format2], minify = config2?.minify ?? !1, outDir = path.relative(cwd, distPath), pathAliases = Object.fromEntries(
    Object.entries(ts2.config?.options.paths || {}).map(([key, val]) => [key, path.resolve(cwd, ts2.config?.options.baseUrl || ".", val[0])])
  ), entries = buildTask.entries.map((entry) => ({
    ...entry,
    name: path.relative(outDir, entry.output).replace(/\.[^/.]+$/, "")
  }), {}), exportIds = _exports && Object.keys(_exports).map((exportPath) => path.join(pkg.name, exportPath)), sourcePaths = _exports && Object.values(_exports).map((e) => path.resolve(cwd, e.source)), replacements = Object.fromEntries(
    Object.entries(config2?.define || {}).map(([key, val]) => [key, JSON.stringify(val)])
  ), { optimizeLodash: enableOptimizeLodash = hasDependency(pkg, "lodash") } = config2?.rollup || {}, defaultPlugins = [
    replace({
      preventAssignment: !0,
      values: {
        ...pkg.name === "@sanity/pkg-utils" ? { ...replacements } : {
          "process.env.PKG_FILE_PATH": (arg) => {
            const sourcePath = `./${path.relative(cwd, arg)}`, entry = entries.find((e) => e.source === sourcePath);
            return entry ? JSON.stringify(
              path.relative(cwd, path.resolve(outDir, entry.name + outputExt))
            ) : (console.error(`could not find source entry: ${sourcePath}`), "null");
          },
          "process.env.PKG_FORMAT": JSON.stringify(format2),
          "process.env.PKG_RUNTIME": JSON.stringify(runtime),
          "process.env.PKG_VERSION": JSON.stringify(process.env.PKG_VERSION || pkg.version),
          ...replacements
        }
      }
    }),
    alias({
      entries: { ...pathAliases }
    }),
    nodeResolve({
      browser: runtime === "browser",
      extensions: [".cjs", ".mjs", ".js", ".jsx", ".json", ".node"],
      preferBuiltins: !0
    }),
    commonjs(),
    json(),
    (isReactCompiler || config2?.babel?.reactCompiler) && babel({
      babelrc: !1,
      presets: ["@babel/preset-typescript"],
      babelHelpers: "bundled",
      extensions: [".ts", ".tsx", ".js", ".jsx"],
      plugins: [["babel-plugin-react-compiler", config2?.reactCompilerOptions || {}]]
    }),
    esbuild({
      jsx: config2?.jsx ?? "automatic",
      jsxFactory: config2?.jsxFactory ?? "createElement",
      jsxFragment: config2?.jsxFragment ?? "Fragment",
      jsxImportSource: config2?.jsxImportSource ?? "react",
      target,
      tsconfig: ctx.ts.configPath || "tsconfig.json",
      treeShaking: !0,
      minifySyntax: config2?.minify !== !1,
      supported: {
        "template-literal": !0
      }
    }),
    Array.isArray(config2?.babel?.plugins) && getBabelOutputPlugin({
      babelrc: !1,
      plugins: config2.babel.plugins
    }),
    enableOptimizeLodash && optimizeLodashImports({
      useLodashEs: format2 === "esm" && hasDependency(pkg, "lodash-es") ? !0 : void 0,
      ...typeof config2?.rollup?.optimizeLodash == "boolean" ? {} : config2?.rollup?.optimizeLodash
    }),
    minify && terser({
      compress: { directives: !1 },
      output: {
        comments: (_node, comment) => {
          const text = comment.value;
          return comment.type === "comment2" ? /@preserve|@license|@cc_on/i.test(text) : !1;
        }
      }
    })
  ].filter(Boolean), userPlugins = config2?.rollup?.plugins, plugins = Array.isArray(userPlugins) ? defaultPlugins.concat(userPlugins) : resolveConfigProperty(config2?.rollup?.plugins, defaultPlugins), hashChunkFileNames = config2?.rollup?.hashChunkFileNames ?? !1, chunkFileNames = `${isReactCompiler ? "_compiled" : isLegacyExports ? "_legacy" : hashChunkFileNames ? "_chunks" : "_chunks-[format]"}/${hashChunkFileNames ? "[name]-[hash]" : "[name]"}${outputExt}`, entryFileNames = isLegacyExports ? "[name].js" : `[name]${outputExt}`;
  return {
    inputOptions: {
      context: cwd,
      external: (id, importer) => {
        if (exportIds?.includes(id))
          return !0;
        if (importer && (id.startsWith(".") || id.startsWith("/"))) {
          const idPath = path.resolve(path.dirname(importer), id);
          if (sourcePaths?.includes(idPath))
            return logger.warn(
              `detected self-referencing import \u2013 treating as external: ${path.relative(
                cwd,
                idPath
              )}`
            ), !0;
        }
        const idParts = id.split("/"), name = idParts[0].startsWith("@") ? `${idParts[0]}/${idParts[1]}` : idParts[0];
        return !!(name && external.includes(name));
      },
      input: entries.reduce((acc, entry) => ({ ...acc, [entry.name]: entry.source }), {}),
      watch: {
        chokidar: {
          usePolling: !0
        }
      },
      plugins,
      treeshake: {
        preset: "recommended",
        propertyReadSideEffects: !1,
        moduleSideEffects: "no-external",
        ...config2?.rollup?.treeshake
      },
      experimentalLogSideEffects: config2?.rollup?.experimentalLogSideEffects
    },
    outputOptions: {
      chunkFileNames,
      compact: minify,
      dir: outDir,
      entryFileNames,
      esModule: !0,
      format: format2,
      interop: "compat",
      sourcemap: config2?.sourcemap ?? !0,
      hoistTransitiveImports: !1,
      minifyInternalExports: minify,
      ...config2?.rollup?.output
    }
  };
}
function hasDependency(pkg, packageName) {
  return pkg.dependencies ? packageName in pkg.dependencies : pkg.peerDependencies ? packageName in pkg.peerDependencies : !1;
}
const rollupLegacyTask = {
  name: (ctx, task) => {
    const entries = task.entries.filter((e) => !e.path.includes("__$$bundle_")), targetLines = task.target.length ? ["  target:", ...task.target.map((t) => `    - ${chalk.yellow(t)}`)] : [], entriesLines = entries.length ? [
      "  entries:",
      ...entries.map(
        (e) => [
          "    - ",
          `${chalk.cyan(path.join(ctx.pkg.name, e.path))}: `,
          `${chalk.yellow(e.source)} ${chalk.gray("\u2192")} ${chalk.yellow(e.output)}`
        ].join("")
      )
    ] : [];
    return [
      "Build legacy exports...",
      `  format: ${chalk.yellow(task.format)}`,
      ...targetLines,
      ...entriesLines
    ].join(`
`);
  },
  exec: (ctx, task) => new Observable((observer) => {
    execPromise$2(ctx, task).then((result) => {
      observer.next(result), observer.complete();
    }).catch((err) => observer.error(err));
  }),
  complete: () => {
  },
  error: (_ctx, _task, err) => {
    console.error(err);
  }
};
async function execPromise$2(ctx, task) {
  const { distPath, files, logger } = ctx, outDir = path.relative(ctx.cwd, distPath), consoleSpy = createConsoleSpy({
    onRestored: (messages) => {
      for (const msg of messages) {
        const text = String(msg.args[0]);
        msg.code !== "CIRCULAR_DEPENDENCY" && (text.startsWith("Dynamic import can only") || text.startsWith("Sourcemap is likely to be incorrect") || (msg.type === "log" && logger.info(...msg.args), msg.type === "warn" && logger.warn(...msg.args), msg.type === "error" && logger.error(...msg.args)));
      }
    }
  });
  try {
    const { inputOptions, outputOptions } = resolveRollupConfig(ctx, task), bundle = await rollup({
      ...inputOptions,
      onwarn(warning) {
        consoleSpy.messages.push({
          type: "warn",
          code: warning.code,
          args: [warning.message]
        });
      }
    }), { output } = await bundle.generate(outputOptions);
    for (const chunkOrAsset of output)
      chunkOrAsset.type === "asset" ? files.push({
        type: "asset",
        path: path.resolve(outDir, chunkOrAsset.fileName)
      }) : files.push({
        type: "chunk",
        path: path.resolve(outDir, chunkOrAsset.fileName)
      });
    await bundle.write(outputOptions), await bundle.close(), consoleSpy.restore();
  } catch (err) {
    throw consoleSpy.restore(), err;
  }
}
const rollupReactCompilerTask = {
  name: (ctx, task) => {
    const entries = task.entries.filter((e) => !e.path.includes("__$$bundle_")), targetLines = task.target.length ? ["  target:", ...task.target.map((t) => `    - ${chalk.yellow(t)}`)] : [], entriesLines = entries.length ? [
      "  entries:",
      ...entries.map(
        (e) => [
          "    - ",
          `${chalk.cyan(path.join(ctx.pkg.name, e.path))}: `,
          `${chalk.yellow(e.source)} ${chalk.gray("\u2192")} ${chalk.yellow(e.output)}`
        ].join("")
      )
    ] : [];
    return ["Build react compiler exports...", ...targetLines, ...entriesLines].join(`
`);
  },
  exec: (ctx, task) => new Observable((observer) => {
    execPromise$1(ctx, task).then((result) => {
      observer.next(result), observer.complete();
    }).catch((err) => observer.error(err));
  }),
  complete: () => {
  },
  error: (_ctx, _task, err) => {
    console.error(err);
  }
};
async function execPromise$1(ctx, task) {
  const { distPath, files, logger } = ctx, outDir = path.relative(ctx.cwd, distPath), consoleSpy = createConsoleSpy({
    onRestored: (messages) => {
      for (const msg of messages) {
        const text = String(msg.args[0]);
        msg.code !== "CIRCULAR_DEPENDENCY" && (text.startsWith("Dynamic import can only") || text.startsWith("Sourcemap is likely to be incorrect") || (msg.type === "log" && logger.info(...msg.args), msg.type === "warn" && logger.warn(...msg.args), msg.type === "error" && logger.error(...msg.args)));
      }
    }
  });
  try {
    const { inputOptions, outputOptions } = resolveRollupConfig(ctx, task), bundle = await rollup({
      ...inputOptions,
      onwarn(warning) {
        consoleSpy.messages.push({
          type: "warn",
          code: warning.code,
          args: [warning.message]
        });
      }
    }), { output } = await bundle.generate(outputOptions);
    for (const chunkOrAsset of output)
      chunkOrAsset.type === "asset" ? files.push({
        type: "asset",
        path: path.resolve(outDir, chunkOrAsset.fileName)
      }) : files.push({
        type: "chunk",
        path: path.resolve(outDir, chunkOrAsset.fileName)
      });
    await bundle.write(outputOptions), await bundle.close(), consoleSpy.restore();
  } catch (err) {
    throw consoleSpy.restore(), err;
  }
}
const rollupTask = {
  name: (ctx, task) => {
    const bundleEntries = task.entries.filter((e) => e.path.includes("__$$bundle_")), entries = task.entries.filter((e) => !e.path.includes("__$$bundle_")), targetLines = task.target.length ? ["  target:", ...task.target.map((t) => `    - ${chalk.yellow(t)}`)] : [], bundlesLines = bundleEntries.length ? [
      "  bundles:",
      ...bundleEntries.map(
        (e) => [
          "    - ",
          `${chalk.yellow(e.source)} ${chalk.gray("\u2192")} ${chalk.yellow(e.output)}`
        ].join("")
      )
    ] : [], entriesLines = entries.length ? [
      "  entries:",
      ...entries.map(
        (e) => [
          "    - ",
          `${chalk.cyan(path.join(ctx.pkg.name, e.path))}: `,
          `${chalk.yellow(e.source)} ${chalk.gray("\u2192")} ${chalk.yellow(e.output)}`
        ].join("")
      )
    ] : [];
    return [
      "Build javascript files...",
      `  format: ${chalk.yellow(task.format)}`,
      ...targetLines,
      ...bundlesLines,
      ...entriesLines
    ].join(`
`);
  },
  exec: (ctx, task) => new Observable((observer) => {
    execPromise(ctx, task).then((result) => {
      observer.next(result), observer.complete();
    }).catch((err) => observer.error(err));
  }),
  complete: () => {
  },
  error: (_ctx, _task, err) => {
    console.error(err);
  }
};
async function execPromise(ctx, task) {
  const { distPath, files, logger } = ctx, outDir = path.relative(ctx.cwd, distPath), consoleSpy = createConsoleSpy({
    onRestored: (messages) => {
      for (const msg of messages) {
        const text = String(msg.args[0]);
        msg.code !== "CIRCULAR_DEPENDENCY" && (text.startsWith("Dynamic import can only") || text.startsWith("Sourcemap is likely to be incorrect") || (msg.type === "log" && logger.info(...msg.args), msg.type === "warn" && logger.warn(...msg.args), msg.type === "error" && logger.error(...msg.args)));
      }
    }
  });
  try {
    const { inputOptions, outputOptions } = resolveRollupConfig(ctx, task), bundle = await rollup({
      ...inputOptions,
      onwarn(warning) {
        consoleSpy.messages.push({
          type: "warn",
          code: warning.code,
          args: [warning.message]
        });
      }
    }), { output } = await bundle.generate(outputOptions);
    for (const chunkOrAsset of output)
      chunkOrAsset.type === "asset" ? files.push({
        type: "asset",
        path: path.resolve(outDir, chunkOrAsset.fileName)
      }) : files.push({
        type: "chunk",
        path: path.resolve(outDir, chunkOrAsset.fileName)
      });
    await bundle.write(outputOptions), await bundle.close(), consoleSpy.restore();
  } catch (err) {
    throw consoleSpy.restore(), err;
  }
}
const rollupWatchTask = {
  name: (ctx, task) => `build javascript files (target ${task.target.join(" + ")}, format ${task.format})
       ${task.entries.map((e) => `${chalk.blue(path.join(ctx.pkg.name, e.path))}: ${e.source} -> ${e.output}`).join(`
       `)}`,
  exec: (ctx, task) => {
    const { inputOptions, outputOptions } = resolveRollupConfig(ctx, task);
    return new Observable((observer) => {
      const watchOptions = {
        ...inputOptions,
        output: outputOptions
      }, watcher = watch$1(watchOptions);
      return watcher.on("event", (event) => {
        observer.next(event);
      }), () => {
        watcher.close();
      };
    });
  },
  complete: (ctx, task, event) => {
    const { logger } = ctx;
    if (event.code === "BUNDLE_END") {
      logger.success(
        `build javascript files (target ${task.target.join(" + ")}, format ${task.format})
       ${task.entries.map((e) => `${chalk.blue(path.join(ctx.pkg.name, e.path))}: ${e.source} -> ${e.output}`).join(`
       `)}`
      ), logger.log("");
      return;
    }
    if (event.code !== "BUNDLE_START" && event.code !== "END" && event.code === "ERROR") {
      logger.error(event.code, event);
      return;
    }
  },
  error: (ctx, _task, err) => {
    const { logger } = ctx;
    err instanceof Error && logger.log(err);
  }
}, buildTaskHandlers = {
  "build:dts": dtsTask,
  "build:js": rollupTask,
  "build:legacy": rollupLegacyTask,
  "build:react-compiler": rollupReactCompilerTask
}, watchTaskHandlers = {
  "watch:dts": dtsWatchTask,
  "watch:js": rollupWatchTask
};
async function build(options) {
  const {
    cwd,
    emitDeclarationOnly,
    strict = !1,
    tsconfig: tsconfigOption,
    clean = !1
  } = options, logger = createLogger(), config2 = await loadConfig({ cwd }), legacyExports = config2?.legacyExports ?? !1, pkg = await loadPkgWithReporting({ cwd, logger, strict, legacyExports }), tsconfig = tsconfigOption || config2?.tsconfig || "tsconfig.json", ctx = await resolveBuildContext({
    config: config2,
    cwd,
    emitDeclarationOnly,
    logger,
    pkg,
    strict,
    tsconfig
  });
  clean && (logger.log(
    `Deleting the \`dist\` folder: './${path.relative(cwd, ctx.distPath)}' before building...`
  ), await rimraf(ctx.distPath));
  const buildTasks = resolveBuildTasks(ctx);
  for (const task of buildTasks) {
    const handler = buildTaskHandlers[task.type], taskName = handler.name(ctx, task), spinner = createSpinner(taskName);
    try {
      const result = await handler.exec(ctx, task).toPromise();
      spinner.complete(), ctx.logger.log(), handler.complete(ctx, task, result);
    } catch (err) {
      if (spinner.error(), err instanceof Error) {
        const RE_CWD = new RegExp(`${cwd}`, "g");
        ctx.logger.error(err.message.replace(RE_CWD, ".")), ctx.logger.log();
      }
      handler.error(ctx, task, err), process.exit(1);
    }
  }
}
function getFilesize(file) {
  const stats = statSync(file);
  return prettyBytes(stats.size);
}
function getFileInfo(cwd, filePath) {
  const p = path.resolve(cwd, filePath), exists = fileExists(p), size = exists ? getFilesize(p) : void 0;
  return { exists, size };
}
function printPackageTree(ctx) {
  const { cwd, exports, logger, pkg } = ctx;
  if (!exports) return;
  logger.log(`${chalk.blue(pkg.name)}@${chalk.green(pkg.version)}`);
  const tree = {};
  pkg.type && (tree.type = chalk.yellow(pkg.type)), pkg.bin && (tree.bin = Object.fromEntries(
    Object.entries(pkg.bin).map(([name, file]) => [chalk.cyan(name), fileInfo(file)])
  ));
  function fileInfo(file) {
    const info = getFileInfo(cwd, file);
    return info.size ? `${chalk.yellow(file)} ${chalk.gray(info.size)}` : `${chalk.gray(file)} ${chalk.red("does not exist")}`;
  }
  tree.exports = Object.fromEntries(
    Object.entries(exports).filter(([, entry]) => entry._exported).map(([exportPath, entry]) => {
      const exp = {
        source: fileInfo(entry.source),
        browser: void 0,
        require: void 0,
        node: void 0,
        import: void 0,
        default: fileInfo(entry.default)
      };
      return entry.browser ? (exp.browser = { source: fileInfo(entry.browser.source) }, entry.browser.import && (exp.browser.import = fileInfo(entry.browser.import)), entry.browser.require && (exp.browser.require = fileInfo(entry.browser.require))) : delete exp.browser, entry.require ? exp.require = fileInfo(entry.require) : delete exp.require, entry.node ? (exp.node = {}, entry.node.source && (exp.node.source = fileInfo(entry.node.source)), entry.node.import && (exp.node.import = fileInfo(entry.node.import)), entry.node.require && (exp.node.require = fileInfo(entry.node.require))) : delete exp.node, entry.import ? exp.import = fileInfo(entry.import) : delete exp.import, [chalk.cyan(path.join(pkg.name, exportPath)), exp];
    })
  ), logger.log(treeify.asTree(tree, !0, !0));
}
async function check(options) {
  const { cwd, strict = !1, tsconfig: tsconfigOption } = options, logger = createLogger(), config2 = await loadConfig({ cwd }), legacyExports = config2?.legacyExports ?? !1, pkg = await loadPkgWithReporting({ cwd, logger, strict, legacyExports }), tsconfig = tsconfigOption || config2?.tsconfig || "tsconfig.json", ctx = await resolveBuildContext({ config: config2, cwd, logger, pkg, strict, tsconfig });
  if (printPackageTree(ctx), strict) {
    const missingFiles = [];
    for (const [, exp] of Object.entries(ctx.exports || {}))
      exp.source && !fileExists(path.resolve(cwd, exp.source)) && missingFiles.push(exp.source), exp.require && !fileExists(path.resolve(cwd, exp.require)) && missingFiles.push(exp.require), exp.import && !fileExists(path.resolve(cwd, exp.import)) && missingFiles.push(exp.import);
    ctx.pkg.types && !fileExists(path.resolve(cwd, ctx.pkg.types)) && missingFiles.push(ctx.pkg.types), missingFiles.length && (logger.error(`missing files: ${missingFiles.join(", ")}`), process.exit(1));
    const exportPaths = {
      require: [],
      import: []
    };
    for (const exp of Object.values(ctx.exports || {}))
      exp._exported && (exp.require && exportPaths.require.push(exp.require), exp.import && exportPaths.import.push(exp.import));
    const external = [
      ...Object.keys(pkg.dependencies || {}),
      ...Object.keys(pkg.devDependencies || {})
    ], consoleSpy = createConsoleSpy();
    exportPaths.import.length && checkExports(exportPaths.import, { cwd, external, format: "esm", logger }), exportPaths.require.length && checkExports(exportPaths.require, { cwd, external, format: "cjs", logger }), consoleSpy.restore();
  }
}
async function checkExports(exportPaths, options) {
  const { cwd, external, format: format2, logger } = options, code = exportPaths.map((id) => format2 ? `import('${id}');` : `require('${id}');`).join(`
`);
  try {
    const esbuildResult = await esbuild$1.build({
      bundle: !0,
      external,
      format: format2,
      logLevel: "silent",
      // otherwise output maps to stdout as we're using stdin
      outfile: "/dev/null",
      platform: "node",
      stdin: {
        contents: code,
        loader: "js",
        resolveDir: cwd
      }
    });
    if (esbuildResult.errors.length > 0) {
      for (const msg of esbuildResult.errors)
        printEsbuildMessage(logger.warn, msg), logger.log();
      process.exit(1);
    }
    const esbuildWarnings = esbuildResult.warnings.filter((msg) => {
      (msg.detail || msg.text).includes("does not affect esbuild's own target setting");
    });
    for (const msg of esbuildWarnings)
      printEsbuildMessage(logger.warn, msg), logger.log();
  } catch (err) {
    if (isEsbuildFailure(err)) {
      const { errors } = err;
      for (const msg of errors)
        printEsbuildMessage(logger.error, msg), logger.log();
    } else err instanceof Error ? (logger.error(err.stack || err.message), logger.log()) : (logger.error(`${err}`), logger.log());
    process.exit(1);
  }
}
function printEsbuildMessage(log, msg) {
  msg.location ? log(
    [
      `${msg.detail || msg.text}
`,
      `${msg.location.line} | ${msg.location.lineText}
`,
      `in ./${msg.location.file}:${msg.location.line}:${msg.location.column}`
    ].join("")
  ) : log(msg.detail || msg.text);
}
function isEsbuildFailure(err) {
  return err instanceof Error && "errors" in err && Array.isArray(err.errors) && err.errors.every(isEsbuildMessage) && "warnings" in err && Array.isArray(err.warnings) && err.warnings.every(isEsbuildMessage);
}
function isEsbuildMessage(msg) {
  return typeof msg == "object" && msg !== null && "text" in msg && typeof msg.text == "string" && "location" in msg && (msg.location === null || typeof msg.location == "object");
}
async function isEmptyDirectory(dirPath) {
  return (await readdir(dirPath)).length === 0;
}
const overridableDefaults = {
  endOfLine: "lf",
  tabWidth: 2,
  useTabs: !1
}, config = {
  ...overridableDefaults,
  printWidth: 100,
  semi: !1,
  singleQuote: !0,
  quoteProps: "consistent",
  bracketSpacing: !1,
  plugins: ["prettier-plugin-packagejson"],
  overrides: [
    {
      files: ["*.json5"],
      options: {
        quoteProps: "preserve",
        singleQuote: !1
      }
    },
    {
      files: ["*.yml"],
      options: {
        singleQuote: !1
      }
    }
  ]
}, RE_NAME = /^(?:@(?:[a-z0-9-*~][a-z0-9-*._~]*)\/)?[a-z0-9-~][a-z0-9-._~]*$/i, defaultTemplate = async ({ cwd, logger, packagePath }) => {
  const gitConfig = await parseGitConfig({ cwd, type: "global" });
  return {
    options: [
      {
        name: "repo",
        type: "string",
        description: "git url",
        validate: (v) => {
          if (!v) return !0;
          try {
            return gitUrlParse(v), !0;
          } catch {
            return "invalid git url";
          }
        },
        parse: (v) => {
          if (!v) return null;
          const result = gitUrlParse(v);
          return { source: result.source, owner: result.owner, name: result.name };
        }
      },
      {
        name: "pkgName",
        type: "string",
        description: "package name",
        initial: (options) => options.repo?.name || void 0,
        validate: (v) => v ? RE_NAME.exec(v) ? !0 : "invalid package name" : "package name is required",
        parse: (v) => {
          if (!v)
            throw new Error("package name is required");
          if (!RE_NAME.exec(v))
            throw new Error("invalid package name");
          const [scope, name] = v.split("/");
          return { scope, name, fullName: v };
        }
      },
      {
        name: "description",
        type: "string",
        description: "package description"
      },
      {
        name: "authorName",
        type: "string",
        description: "package author name",
        initial: gitConfig?.user?.name
      },
      {
        name: "authorEmail",
        type: "string",
        description: "package author email",
        initial: gitConfig?.user?.email
      },
      {
        name: "license",
        type: "string",
        description: "package license",
        initial: "MIT",
        validate: (v) => v ? !0 : "license is required"
      }
    ],
    features: [
      {
        name: "eslint",
        optional: !0,
        initial: !0
      },
      {
        name: "prettier",
        optional: !0,
        initial: !0
      },
      {
        name: "typescript",
        optional: !0,
        initial: !0
      }
    ],
    async getFiles(options, features) {
      const { pkgName, repo } = options, { fullName: name } = pkgName, author = [options.authorName, options.authorEmail && `<${options.authorEmail}>`].filter(Boolean).join(" ") ?? void 0, pkgJson = {
        name,
        version: "0.0.0",
        description: options.description ?? void 0,
        keywords: [],
        homepage: void 0,
        bugs: void 0,
        repository: void 0,
        license: options.license,
        author,
        sideEffects: !1,
        type: "module",
        exports: {
          ".": {
            source: features.typescript ? "./src/index.ts" : "./src/index.js",
            require: "./dist/index.cjs",
            default: "./dist/index.js"
          },
          "./package.json": "./package.json"
        },
        main: "./dist/index.cjs",
        module: "./dist/index.js",
        types: void 0,
        files: ["dist", "src"],
        scripts: {
          build: "pkg build --strict --clean --check",
          format: features.prettier ? "prettier --write --cache --ignore-unknown ." : void 0
        },
        "lint-staged": features.prettier ? {
          "*": ["prettier --write --cache --ignore-unknown"]
        } : void 0,
        browserslist: "extends @sanity/browserslist-config",
        prettier: features.prettier ? "@sanity/prettier-config" : void 0,
        dependencies: {},
        devDependencies: {
          "@sanity/pkg-utils": "^6",
          "@sanity/prettier-config": features.prettier ? "^1" : void 0,
          "@typescript-eslint/eslint-plugin": void 0,
          "@typescript-eslint/parser": void 0,
          eslint: void 0,
          "eslint-config-prettier": void 0,
          "eslint-plugin-import": void 0,
          "eslint-plugin-prettier": void 0,
          "eslint-plugin-simple-import-sort": void 0,
          "lint-staged": "^15",
          prettier: features.prettier ? "^3" : void 0,
          typescript: void 0
        },
        engines: {
          node: ">=18.0.0"
        }
      }, files = [];
      if (files.push({
        name: ".editorconfig",
        contents: outdent`
        root = true

        [*]
        charset = utf-8
        indent_style = space
        indent_size = 2
        end_of_line = lf
        insert_final_newline = true
        trim_trailing_whitespace = true
        `
      }), files.push({
        name: ".gitignore",
        contents: outdent`
        *.local
        *.log
        *.tgz

        .DS_Store
        dist
        etc
        node_modules
        `
      }), features.prettier && files.push({
        name: ".prettierignore",
        contents: outdent`
          dist
          pnpm-lock.yaml
          `
      }), repo && (pkgJson.repository = {
        type: "git",
        url: `git+ssh://git@${repo.source}/${repo.owner}/${repo.name}.git`
      }, pkgJson.bugs = {
        url: `https://${repo.source}/${repo.owner}/${repo.name}/issues`
      }, pkgJson.homepage = `https://${repo.source}/${repo.owner}/${repo.name}#readme`), features.typescript) {
        pkgJson.types = "./dist/index.d.ts", pkgJson.scripts = {
          ...pkgJson.scripts,
          "ts:check": "tsc --noEmit"
        };
        const devDependencies = pkgJson.devDependencies;
        isRecord(devDependencies) && (devDependencies.typescript = "^5.4");
      }
      if (features.eslint) {
        const eslintConfig = {
          root: !0,
          env: {
            browser: !0,
            es6: !0,
            node: !0
          },
          extends: [
            "eslint:recommended",
            features.prettier ? "plugin:prettier/recommended" : void 0
          ].filter(Boolean),
          parserOptions: {
            ecmaVersion: 2020,
            sourceType: "module"
          },
          plugins: [
            "import",
            "simple-import-sort",
            features.prettier ? "prettier" : void 0
          ].filter(Boolean),
          rules: {
            "no-console": "error",
            "no-shadow": "error",
            "no-warning-comments": ["warn", { location: "start", terms: ["todo", "fixme"] }],
            "quote-props": ["warn", "consistent-as-needed"],
            "simple-import-sort/exports": "warn",
            "simple-import-sort/imports": "warn",
            strict: ["warn", "global"]
          }
        };
        if (files.push({
          name: ".eslintignore",
          contents: outdent`
          dist
          `
        }), pkgJson.scripts = {
          ...pkgJson.scripts,
          lint: features.typescript ? "eslint . --ext .cjs,.js,.ts,.tsx" : "eslint . --ext .cjs,.js"
        }, pkgJson.devDependencies = {
          ...pkgJson.devDependencies,
          eslint: "^8",
          "eslint-config-prettier": features.prettier ? "^9" : void 0,
          "eslint-plugin-import": "^2",
          "eslint-plugin-prettier": features.prettier ? "^5" : void 0,
          "eslint-plugin-simple-import-sort": "^12"
        }, features.typescript) {
          pkgJson.devDependencies = {
            ...pkgJson.devDependencies,
            "@typescript-eslint/eslint-plugin": "^7",
            "@typescript-eslint/parser": "^7"
          };
          const eslintConfigOverride = {
            files: ["**/*.ts", "**/*.tsx"],
            parser: "@typescript-eslint/parser",
            parserOptions: {
              project: ["./tsconfig.json"]
            },
            extends: [
              "eslint:recommended",
              features.prettier ? "plugin:prettier/recommended" : void 0,
              "plugin:@typescript-eslint/eslint-recommended",
              "plugin:@typescript-eslint/recommended"
            ].filter(Boolean),
            plugins: [
              "import",
              "@typescript-eslint",
              "simple-import-sort",
              features.prettier ? "prettier" : void 0
            ].filter(Boolean),
            rules: {
              "@typescript-eslint/explicit-module-boundary-types": "error",
              "@typescript-eslint/interface-name-prefix": "off",
              "@typescript-eslint/member-delimiter-style": "off",
              "@typescript-eslint/no-empty-interface": "off"
            }
          };
          eslintConfig.overrides = [eslintConfigOverride];
        }
        files.push({
          name: ".eslintrc.cjs",
          contents: await format(
            resolve(packagePath, ".eslintrc.cjs"),
            outdent`
            'use strict'

            /** @type import('eslint').Linter.Config */
            module.exports = ${JSON.stringify(eslintConfig, null, 2)}
            `,
            config
          )
        });
      }
      features.typescript && (files.push({
        name: "tsconfig.settings.json",
        contents: await format(
          resolve(packagePath, "tsconfig.settings.json"),
          outdent`
            {
              "extends": "@sanity/pkg-utils/tsconfig/strictest.json",
              "compilerOptions": {
                "rootDir": ".",
                "outDir": "./dist"
              }
            }
            `,
          config
        )
      }), files.push({
        name: "tsconfig.dist.json",
        contents: await format(
          resolve(packagePath, "tsconfig.dist.json"),
          outdent`
            {
              "extends": "./tsconfig.settings",
              "include": ["./src"],
              "exclude": ["./src/**/*.test.ts"]
            }
            `,
          config
        )
      }), files.push({
        name: "tsconfig.json",
        contents: await format(
          resolve(packagePath, "tsconfig.json"),
          outdent`
            {
              "extends": "./tsconfig.settings",
              "include": ["./**/*.cjs", "./**/*.ts", "./**/*.tsx"],
              "exclude": ["./node_modules"]
            }
            `,
          config
        )
      })), features.typescript ? (files.push({
        name: "package.config.ts",
        contents: await format(
          resolve(packagePath, "package.config.ts"),
          outdent`
            import {defineConfig} from '@sanity/pkg-utils'

            // https://github.com/sanity-io/pkg-utils#configuration
            export default defineConfig({
              // the path to the tsconfig file for distributed builds
              tsconfig: 'tsconfig.dist.json',
            })
            `,
          config
        )
      }), files.push({
        name: "src/index.ts",
        contents: await format(
          resolve(packagePath, "src/index.ts"),
          outdent`
            /** @public */
            export function main(): void {
              //
            }
            `,
          config
        )
      })) : (files.push({
        name: "package.config.js",
        contents: await format(
          resolve(packagePath, "package.config.js"),
          outdent`
            import {defineConfig} from '@sanity/pkg-utils'

            export default defineConfig({
              extract: {
                rules: {
                  // do not require internal members to be prefixed with \`_\`
                  'ae-internal-missing-underscore': 'off',
                },
              },
            })
            `,
          config
        )
      }), files.push({
        name: "src/index.js",
        contents: await format(
          resolve(packagePath, "src/index.js"),
          outdent`
            /** @public */
            export function main() {
              //
            }
            `,
          config
        )
      }));
      try {
        pkgJson.dependencies = await resolveLatestDeps(pkgJson.dependencies ?? {});
      } catch (error) {
        logger.warn(error instanceof Error ? error.message : error);
      }
      try {
        pkgJson.devDependencies = await resolveLatestDeps(pkgJson.devDependencies ?? {});
      } catch (error) {
        logger.warn(error instanceof Error ? error.message : error);
      }
      return files.push({
        name: "package.json",
        contents: await format(
          resolve(packagePath, "package.json"),
          JSON.stringify(pkgJson, null, 2),
          config
        )
      }), files;
    }
  };
};
function format(filepath, input, prettierOptions) {
  return prettier.format(input, { ...prettierOptions, plugins: [], filepath });
}
async function resolveLatestDeps(deps) {
  const depsEntries = Object.entries(deps), latestDeps = {};
  for (const entry of depsEntries) {
    const [name, version] = entry;
    if (version) {
      const latestVersion = await getLatestVersion(name, version);
      latestDeps[name] = latestVersion ? `^${latestVersion}` : version;
    }
  }
  return latestDeps;
}
async function init(options) {
  if (!options.cwd)
    throw new Error("Missing required option: cwd");
  if (!options.path)
    throw new Error("Missing required option: path");
  const logger = createLogger(), packagePath = resolve(options.cwd, options.path);
  await ensurePackagePath(packagePath), await createFromTemplate({
    cwd: options.cwd,
    logger,
    template: defaultTemplate,
    packagePath
  });
}
async function ensurePackagePath(packagePath) {
  if (!fileExists(packagePath)) {
    await mkdirp(packagePath);
    return;
  }
  if (!(await lstat(packagePath)).isDirectory())
    throw new Error("the package path is a file, not a directory");
  if (!await isEmptyDirectory(packagePath))
    throw new Error("the package directory is not empty");
}
function resolveWatchTasks(ctx) {
  const { config: config2, cwd, pkg, target } = ctx, tasks = [], exports = Object.entries(ctx.exports || {}).map(
    ([_path, exp]) => ({ _path, ...exp })
  ), dtsTask2 = {
    type: "watch:dts",
    entries: []
  }, rollupTasks = {};
  function addRollupTaskEntry(format2, runtime, entry) {
    const buildId = `${format2}:${runtime}`;
    rollupTasks[buildId] ? rollupTasks[buildId].entries.push(entry) : rollupTasks[buildId] = {
      type: "watch:js",
      buildId,
      entries: [entry],
      runtime,
      format: format2,
      target: target[runtime]
    };
  }
  for (const exp of exports) {
    const importId = path.join(pkg.name, exp._path);
    exp.source?.endsWith(".ts") && dtsTask2.entries.push({
      importId,
      exportPath: exp._path,
      sourcePath: exp.source,
      targetPaths: getTargetPaths(pkg.type, exp)
    }), exp.browser?.source?.endsWith(".ts") && dtsTask2.entries.push({
      importId,
      exportPath: exp._path,
      sourcePath: exp.browser.source,
      targetPaths: getTargetPaths(pkg.type, exp.browser)
    }), exp.node?.source?.endsWith(".ts") && dtsTask2.entries.push({
      importId,
      exportPath: exp._path,
      sourcePath: exp.node.source,
      targetPaths: getTargetPaths(pkg.type, exp.node)
    });
  }
  for (const exp of exports) {
    const output = exp.require;
    output && addRollupTaskEntry("commonjs", ctx.runtime, {
      path: exp._path,
      source: exp.source,
      output
    });
  }
  for (const exp of exports) {
    const output = exp.browser?.require;
    output && addRollupTaskEntry("commonjs", "browser", {
      path: exp._path,
      source: exp.browser?.source || exp.source,
      output
    });
  }
  for (const exp of exports) {
    const output = exp.import;
    output && addRollupTaskEntry("esm", ctx.runtime, {
      path: exp._path,
      source: exp.source,
      output
    });
  }
  for (const exp of exports) {
    const output = exp.browser?.import;
    output && addRollupTaskEntry("esm", "browser", {
      path: exp._path,
      source: exp.browser?.source || exp.source,
      output
    });
  }
  if (dtsTask2.entries.length && tasks.push(dtsTask2), tasks.push(...Object.values(rollupTasks)), config2?.legacyExports) {
    for (const exp of exports)
      if (exp._exported && exp._path !== ".") {
        const relativeTargetPath = (exp.browser?.import || exp.import || "").replace(
          /\.[^/.]+$/,
          ""
        );
        relativeTargetPath && fs$1.writeFileSync(
          path.resolve(cwd, `${exp._path}.js`),
          ["// AUTO-GENERATED \u2013 DO NOT EDIT", `export * from '${relativeTargetPath}'`, ""].join(
            `
`
          )
        );
      }
  }
  return tasks;
}
function globFiles(patterns) {
  return globby(patterns.map((pattern) => pattern.split(path.sep).join(path.posix.sep)));
}
function watchFiles(patterns) {
  return new Observable((observer) => {
    const watcher = chokidar.watch(patterns, {
      ignoreInitial: !0
    });
    function handleFileEvent(type, file) {
      type === "error" || file instanceof Error ? observer.error(file) : observer.next({ type, file });
    }
    return watcher.on("all", handleFileEvent), () => {
      watcher.off("all", handleFileEvent), watcher.close();
    };
  });
}
async function watchConfigFiles(options) {
  const { cwd, logger } = options, initialFiles = await globFiles([
    path.resolve(cwd, "package.json"),
    path.resolve(cwd, "package.config.cjs"),
    path.resolve(cwd, "package.config.js"),
    path.resolve(cwd, "package.config.ts")
  ]);
  return watchFiles([
    path.resolve(cwd, "package.json"),
    path.resolve(cwd, "package.config.cjs"),
    path.resolve(cwd, "package.config.js"),
    path.resolve(cwd, "package.config.ts")
  ]).pipe(
    scan((files, fileEvent) => fileEvent.type === "add" ? files.concat(fileEvent.file) : fileEvent.type === "unlink" ? files.filter((f) => f !== fileEvent.file) : fileEvent.type === "change" ? (logger.log(
      "--------------------------------------------------------------------------------"
    ), logger.info(path.relative(cwd, fileEvent.file), "changed"), logger.log(""), files.slice(0)) : files, initialFiles),
    startWith(initialFiles),
    distinctUntilChanged()
  );
}
async function watch(options) {
  const { cwd, strict = !1, tsconfig: tsconfigOption } = options, logger = createLogger();
  (await watchConfigFiles({ cwd, logger })).pipe(
    switchMap(async (configFiles) => {
      if (!configFiles.map((f) => path.relative(cwd, f)).find((f) => f === "package.json"))
        throw new Error("missing package.json");
      const config2 = await loadConfig({ cwd }), legacyExports = config2?.legacyExports ?? !1, pkg = await loadPkgWithReporting({ cwd, logger, strict, legacyExports }), tsconfig = tsconfigOption || config2?.tsconfig || "tsconfig.json";
      return resolveBuildContext({ config: config2, cwd, logger, pkg, strict, tsconfig });
    })
  ).subscribe(async (ctx) => {
    const watchTasks = resolveWatchTasks(ctx);
    for (const task of watchTasks) {
      const handler = watchTaskHandlers[task.type];
      handler.exec(ctx, task).subscribe({
        error: (err) => {
          ctx.logger.error(err), ctx.logger.log(), process.exit(1);
        },
        next: (result) => {
          handler.complete(ctx, task, result);
        },
        complete: () => {
          ctx.logger.success(handler.name(ctx, task)), ctx.logger.log();
        }
      });
    }
  });
}
export {
  DEFAULT_BROWSERSLIST_QUERY,
  build,
  buildTaskHandlers,
  check,
  createFromTemplate,
  createLogger,
  defineConfig,
  defineTemplateOption,
  dtsTask,
  dtsWatchTask,
  getExtractMessagesConfig,
  init,
  isRecord,
  loadConfig,
  loadPkg,
  loadPkgWithReporting,
  loadTSConfig,
  parseExports,
  parseStrictOptions,
  pkgExtMap,
  resolveBuildTasks,
  resolveConfigProperty,
  rollupLegacyTask,
  rollupReactCompilerTask,
  rollupTask,
  rollupWatchTask,
  strictOptions,
  toggle,
  watch,
  watchTaskHandlers
};
//# sourceMappingURL=index.js.map
